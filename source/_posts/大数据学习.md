---
title: 大数据平台
tags:
  - 大数据
categories: 技术
abbrlink: 27q31qqw
date: 2024-01-18 00:00:00
---

## 起始
由于目前在NAVER music data部门，虽然目前只做了大数据可视化这一块工作。但是因自身对整个数据流的兴趣，从而产生了对整个大数据架构的兴趣和学习。
其中有错误的地方，希望读者指正，在后期的学习过程中，会继续更新这篇文章。
以下是我理解的大数据的一种可行性基础架构。

## 数据用途
以下都是采集用户数据、分析、反馈用户的例子：
* 许多电商平台会根据用户的购买、搜索、浏览，在首页给用户推荐商品或推送相应广告。
* 许多智能设备，手表手环等，采集用户数据(心率、血氧等)，给予用户健康提醒。
* 在交通方面，通过大数据采集用户乘坐流量，来增加航班或高铁等。
* 在金融行业，利用大数据分析用户信用，交易等，来对用户进行风险评估。

其实依靠大数据的还有很多很多，这里不一一举例子。

### 数据采集
![](/images/big_data/data_collect.png)

在数据采集过程中，Web/Android/IOS等数据，通过调用后端API把采集的用户行为数据存储到Kafaka。
这里的Load Balance前置，是防止大量请求做的负载均衡，每个公司有自己的负载均衡，如果没有，可以使用云服务商的或nginx。
Kafaka是大数据日志采集用的最多的，以下是它的优点：
* Kafka 能够处理极大量的数据，具有出色的吞吐量和低延迟。
* Kafka 提供了水平扩展的能力，可以通过添加更多的节点来扩展系统，以处理不断增长的数据流。 这里如果出现日志堆积，Kafaka是很好的选择。
* Kafka 通过数据的副本和分布式设计，提供了高可靠性和容错性，同时是开源项目，有庞大的社区支持。
注意：
* 前端数据采集在发送HTTP请求时，需要设置超时时间，防止API因并发数量过大导致响应超时，影响业务系统。
* 后端API需要使用异步投递到Kafaka，不处理业务，加速响应请求，这里也体现了业务解耦的重要性。

## 数据存储
![](/images/big_data/data_save.png)

这里大数据存储使用Hadoop。图中Customers从Kafaka消息队列里拿到数据、计算、spark整理字段、spark使用hive通过sql的形式插入数据到HDFS。
Hadoop优点：
* 分布式存储、成本低
    * 能够在大量的廉价硬件上存储巨大的数据集，并提供高可靠性和容错性
* 开源生态系统、社区支持庞大
    * Hadoop 生态系统庞大而活跃，包括了许多工具和框架，如Hive、Pig、HBase等，可以满足不同的数据处理需求。
    * 在搭建好Hadoop后，需要用户安装Hive, Hive非常方便，让我们在Hadoop使用SQL方式创建表，同时进行增删改查操作
    * 在创建完表之后，需要搭建一套应用程序，处理存储在Kafaka上的用户行为数据

注意：
* 这里整个应用程序是通过spark submit传送到Hadoop ，作为Hadoop的子项目启动。
* spark任务在会在 HDFS 上创建中间结果、检查点数据或其他临时文件。
* 使用spark submit提交的数据，在执行完成后，其中相关的应用程序和包会被当作零时文件清除，通过释放存储空间来保持HDFS的整洁。

## 数据分析
![](/images/big_data/data_analysis.png)

在上一次数据存储过程中，经过一次数据整理后的数据存储到HDFS中，目前存储在HDFS的数据基本满足可读性。
但对于完整的数据分析远远不够。这里需要对数据进行二次或多次数据分析处理。
* 通过上图可以看出，存储在HDFS的数据，通过很多Jenkins批处理任务，来进行不同业务和不同维度的分析。
    * Jenkins通过执行不同的Job任务，把不同的业务处理程序推送到Hadoop，来处理不同业务。最终通过Hadoop Jobs把不同的统计数据存储到MySQL。
* 在第二个图中，详细讲解了程序运行的流程，介绍如何处理和分析数据。
    * Hadoop Jobs从HDFS读取业务数据，使用Hive，让它以执行SQL的方式把数据读取出来。
    * 通过Hive读取的数据，再通过Spark在内存中对数据的行列进行数据分析(增删改查)，分析出业务所需要的数据。
    * 将分析出来的数据，第一步通过JDBC, 来存储到MySQL，第二步，通过异步Async的方式降数据存储到Kafaka中,以便进行二次分析。
    * 二次分析，还是通过Customers读取Kafaka队列里的业务数据，业务数据经过Spark/Hive的转换和分析，把计算出来的数据通过SQL的方式存储到HDFS。

经过一次，二次，多次的数据分析，形成业务所需要的数据。这里一般是按照年、月、日、时、分形成的统计数据。把分析好的数据存储到MySQL中，方便数据展示。

## 数据可视化和数据接口
![](/images/big_data/data_visualization_interface.png)

经历过一次或多次数据分析，完善的统计数据已经存储到MySQL了，这个时候需要把数据通过网页展示出来，方便数据查看。
同时这个数据也可以通过API接口，提供给第三方服务使用。
这里前端可以采用Vue。 后端可以采用Python Django。

Vue优点：
* 轻量级和简单
    * Vue.js的核心库只有20KB左右，非常轻量级，易于学习和使用。使用组件化开发，类似一个页面一个组件。
* 响应式数据绑定 
    * Vue.js采用数据绑定技术，使得数据与视图之间的同步变得非常容易。当数据发生变化时，视图会自动更新，简化了开发人员的工作。
* 社区支持
    * Vue.js拥有庞大的社区和支持，使得开发人员可以找到大量的资源和帮助。Vue.js的文档也非常完整，易于理解和使用。

Django优点：
* 功能强大
    * Django自带了大量常用工具和框架，如数据库访问组件、模板语言、后台管理系统等，可轻松、迅速开发出一个功能齐全的Web应用。
* 可维护性高和安全性
    * Django提供了很多可重用的组件，使代码具有高度可维护性。同时也提供了很多安全功能，如跨站请求伪造(CSRF)保护和密码安全性。
* 文档完善
    * Django已发展十余年，具有广泛的实践案例，同时Django提供完善的在线文档，Django用户能够更容易地找到问题的解决方案。

1. 上图的第一个图，展示了用户访问数据平台的主要流程
* 用户通过浏览器访问数据平台，浏览器通过DNS解析域名,访问 Web服务。
* 详细流程如下： 
    * 前端使用Vue框架编写代码，安装好相应的包之后，build编译生成相关静态页面html/css/js。 
    * Nginx 挂载html/css/js
    * 浏览器发送的请求访问Nginx，Nginx返回对应静态文件，浏览器通过返回的静态文件加载出页面，显示给用户。
    * 页面初始化或用户请求对应统计数据，访问API Server。
    * API Server通过Nginx转发对应请求到UWSGI服务。
    * UWSGI 访问Django服务，Django服务请求MySQL对应表数据，然后整理出来返回数据。
通过以上流程用户就可以通过浏览器页面，查看到对应的统计数据。

2. 上图第二个图，展示了第三方服务通过API访问业务数据流程，API Server流程介绍如上(1.5, 1.6)。

## 总结和思考
* 以上就是大数据从数据采集到最终数据展示和提供接口的主要流程。总的来说大数据处理流程很长，用的工具也很多，包含很多技术。也间接证明了处理数据的不容易。
大数据处理的每个环节都很重要。要深入研究它，需要花费很长时间。
* 希望未来大数据可以与BI和AI结合，提供更加高级的数据挖掘和分析。
* 总结：HDFS作为数据存储基础，Spark作为数据处理和分析的重要工具，MySQL作为多次数据分析的最终存储，Django+Vue作为数据展示的最终平台。
* 下次有机会分享下数据处理和分析的核心Spark。